{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "custom_transformers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOJQauCnAGbbS6SF5cWlIRX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stepthom/869_course/blob/main/pipeline/custom_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "500rRBuTjymu"
      },
      "source": [
        "# Custom Transformers\n",
        "\n",
        "- Stephen W. Thomas\n",
        "- Used for MMA 869, MMAI 869, and GMMA 869\n",
        "\n",
        "For an overview of pipelines in general, read this tutorial first: [slides_pipeline.ipynb](https://github.com/stepthom/869_course/blob/main/pipeline/slides_pipeline.ipynb)\n",
        "\n",
        "Sci-kit learn has a lot of [great transformers](https://scikit-learn.org/stable/data_transforms.html) for your pipeline, but sometimes you need something custom.  \n",
        "\n",
        "This tutorial shows how to create custom transformers for your pipeline.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K7ftsqzkXvr"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Make numpy's printing more beautiful\n",
        "np.set_printoptions(suppress=True)\n",
        "\n",
        "# Make sure Jupyter prints out more\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAl7cMt_kc0S",
        "outputId": "91e203b7-7ac5-471f-82dc-b584326e3883"
      },
      "source": [
        "import sklearn\n",
        "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The scikit-learn version is 0.22.2.post1.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8de-csRMkeQl",
        "outputId": "7e630ccd-de97-44a7-e7c7-d515fc4c3cc6"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/stepthom/869_course/main/data/generated_german.csv')\n",
        "\n",
        "# To keep this tutorial simple, and make things easy to print, let's only work \n",
        "# with a few features.\n",
        "keep_features = ['City', 'Sex', 'Duration', 'Amount', 'BadCredit']\n",
        "\n",
        "df = df[keep_features]\n",
        "df.info()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 5 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   City       1000 non-null   object\n",
            " 1   Sex        1000 non-null   object\n",
            " 2   Duration   1000 non-null   int64 \n",
            " 3   Amount     1000 non-null   int64 \n",
            " 4   BadCredit  1000 non-null   int64 \n",
            "dtypes: int64(3), object(2)\n",
            "memory usage: 39.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nYu1U4PFke9e",
        "outputId": "c5afd113-0aa8-4447-9289-fb8f9754ac6a"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>City</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Amount</th>\n",
              "      <th>BadCredit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>North Judithbury</td>\n",
              "      <td>M</td>\n",
              "      <td>6</td>\n",
              "      <td>2104</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>East Jill</td>\n",
              "      <td>F</td>\n",
              "      <td>48</td>\n",
              "      <td>10712</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>West Michael</td>\n",
              "      <td>M</td>\n",
              "      <td>12</td>\n",
              "      <td>3773</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>North Judithbury</td>\n",
              "      <td>M</td>\n",
              "      <td>42</td>\n",
              "      <td>14188</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ramirezstad</td>\n",
              "      <td>M</td>\n",
              "      <td>24</td>\n",
              "      <td>8766</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               City Sex  Duration  Amount  BadCredit\n",
              "0  North Judithbury   M         6    2104          0\n",
              "1         East Jill   F        48   10712          1\n",
              "2      West Michael   M        12    3773          0\n",
              "3  North Judithbury   M        42   14188          0\n",
              "4       Ramirezstad   M        24    8766          1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bWHDOTGkkVq"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df.drop(['BadCredit'], axis=1)\n",
        "y = df['BadCredit']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P6OGKHIm9lY"
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "# All custom transformers have the following basic structure.\n",
        "# - It is a class that inherits from BaseEstimator and TransformerMixin\n",
        "# - It has at least three methods: __init__(), fit(), and transform()\n",
        "# - It can have more helper methods\n",
        "# - The __init__() is called when you first create the transformer. You can\n",
        "#   pass in custom parameter values here.\n",
        "# - The __init__() method returns nothing.\n",
        "# - The fit() method must return self.\n",
        "# - The transform method must return a dataframe and/or numpy array\n",
        "\n",
        "\n",
        "class MyNumericCapper(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    # Caps a given numeric column(s) to a certain number\n",
        "    # E.g., any value greater than max_val becomes max_val\n",
        "    #\n",
        "    # Note that there was a design choice: either have the user\n",
        "    # pass in the names of the columns to operate one (which I've done here), \n",
        "    # or just operate on all the columns (and have the user be responsible for\n",
        "    # passing in a subset of the dataframe). Pros and cons to each and there's\n",
        "    # note a singe best answer.\n",
        "\n",
        "    def __init__(self, num_cols=None, max_val=0):\n",
        "        self.num_cols = num_cols\n",
        "        self.max_val = max_val\n",
        "        \n",
        "    def fit(self, X, y=None):\n",
        "        # Nothing to do during fit in this simple transformer!\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "\n",
        "        # It's common practice to copy X, so we don't accidentally modify the \n",
        "        # original and cause downstream confusion\n",
        "        _X = X.copy()\n",
        "        \n",
        "        for col in self.num_cols:\n",
        "            _X[col] =  _X[col].apply(lambda x: x if x <= self.max_val else self.max_val)\n",
        "        \n",
        "        return _X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8TAQMgpnHOd"
      },
      "source": [
        "# Another example, slightly more complicated.\n",
        "\n",
        "class MyCategoryCoalescer(BaseEstimator, TransformerMixin):\n",
        "    # Coalesces (smushes/condenses) rare levels of a categorical \n",
        "    # feature into \"__OTHER__\".\n",
        "    #\n",
        "    # Will leave the `keep_top` most frequent levels unchanged; the rest\n",
        "    # will be changed to `\"__OTHER__\"`.\n",
        "    #\n",
        "    # Note that there was a design choice: either have the user\n",
        "    # pass in the names of the columns to operate one (which I've done here), \n",
        "    # or just operate on all the columns (and have the user be responsible for\n",
        "    # passing in a subset of the dataframe). Pros and cons to each and there's\n",
        "    # note a singe best answer.\n",
        "    \n",
        "    def __init__(self, cat_cols=[], keep_top=25, ):\n",
        "        self.cat_cols = cat_cols\n",
        "        self.keep_top = keep_top\n",
        "        \n",
        "        # For each cat_col, this dict will hold an list of the most-frequent \n",
        "        # levels\n",
        "        self.top_n_values = {}\n",
        "            \n",
        "    def get_top_n_values(self, X, col, n=5):\n",
        "        # A helper function to do the actual work.\n",
        "\n",
        "        # Get the sorted value counts for the column\n",
        "        vc = X[col].value_counts(sort=True, ascending=False)\n",
        "\n",
        "        # Get the actual values\n",
        "        vals = list(vc.index)\n",
        "        if len(vals) > n:\n",
        "            top_values = vals[0:n]\n",
        "        else:\n",
        "            top_values =  vals\n",
        "\n",
        "        # Debug printing.\n",
        "        print(\"Top n={} values for column={}:\".format(n, col))\n",
        "        print(top_values)\n",
        "        return top_values\n",
        "    \n",
        "    def fit(self, X, y=None):\n",
        "\n",
        "        # Find the top n values for each cateogircal column\n",
        "        for col in self.cat_cols:\n",
        "            self.top_n_values[col] = self.get_top_n_values(X, col, n=self.keep_top)\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X, y=None):\n",
        "        _X = X.copy()\n",
        "        _X[self.cat_cols] = _X[self.cat_cols].astype('category')\n",
        "        for c in self.cat_cols:\n",
        "            _X[c] = _X[c].cat.add_categories('__OTHER__')\n",
        "            _X.loc[~_X[c].isin(self.top_n_values[c]), c] = \"__OTHER__\"\n",
        "        return _X"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV5BDw9hkngP"
      },
      "source": [
        "# The Pipeline\n",
        "\n",
        "Now we create a pipeline that uses the above custom transformers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ySfHhZ1kmuf"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.compose import make_column_selector\n",
        "\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "                                      \n",
        "    # Here is where we add our custom capper!\n",
        "    ('capper', MyNumericCapper(num_cols=['Duration'], max_val=42)),\n",
        "    ('imputer', SimpleImputer()),\n",
        "\n",
        "    # Not going to scale in this example, so we can visually inspect the results\n",
        "    # of the capper more easily.\n",
        "    #('scaler', StandardScaler()),\n",
        "    ])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "                                          \n",
        "      # Here is where we add our custom coalescer!\n",
        "      ('coalescer', MyCategoryCoalescer(cat_cols=['City'], keep_top=5)),\n",
        "      ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
        "      ])\n",
        "\n",
        "preprocessor1 = Pipeline(steps=[\n",
        "      ('ct', ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('cat', categorical_transformer, make_column_selector(dtype_include=['category', object])),\n",
        "            ('num', numeric_transformer, make_column_selector(dtype_include=['number'])),\n",
        "            ],\n",
        "            remainder = 'passthrough', \n",
        "            sparse_threshold=0)),\n",
        "    ])\n",
        "\n",
        "# Note: we would normally include a classifier/regressor in our pipeline,\n",
        "# but since this tutorial is just for learning about data preprocessing etc., \n",
        "# we will exclude it.\n",
        "\n",
        "pipe1 = Pipeline(steps=[('preprocessor', preprocessor1)])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k53xPZpopKcd",
        "outputId": "428133e2-ae3c-47f9-be46-890290991dd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# The pipe is created! Let's fit it to the training data.\n",
        "\n",
        "pipe1 = pipe1.fit(X_train, y_train)\n",
        "\n",
        "# Now, let's use the pipe to transform the training and testing/.\n",
        "X_train_transformed = pipe1.transform(X_train)\n",
        "X_test_transformed  = pipe1.transform(X_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top n=5 values for column=City:\n",
            "['North Judithbury', 'East Jill', 'New Roberttown', 'East Jessetown', 'Lisatown']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUh-jvR9pbxg",
        "outputId": "144834c3-6384-4534-aca1-04573743da88"
      },
      "source": [
        "# Brilliant! Now, let's inspect the results to see what happened. Let's look at the first row of data.\n",
        "\n",
        "# First, let's look at the \"raw\" data.\n",
        "print(\"Raw Data:\")\n",
        "print(X_train.iloc[0, :])\n",
        "\n",
        "# Now, let's look at the same row, now transformed.\n",
        "print(\"\\nTransformed Data:\")\n",
        "print(X_train_transformed[0,:])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Data:\n",
            "City        North Judithbury\n",
            "Sex                        M\n",
            "Duration                  60\n",
            "Amount                 12305\n",
            "Name: 29, dtype: object\n",
            "\n",
            "Transformed Data:\n",
            "[    0.     0.     0.     0.     1.     0.     0.     1.    42. 12305.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQfNPDMhtEEW",
        "outputId": "5ab5aee8-0d41-41fd-c966-b5463db5f985"
      },
      "source": [
        "# Now, let's inspect the results of another row.\n",
        "\n",
        "print(\"Raw Data:\")\n",
        "print(X_train.iloc[3, :])\n",
        "\n",
        "print(\"\\nTransformed Data:\")\n",
        "print(X_train_transformed[3,:])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw Data:\n",
            "City        North Noahstad\n",
            "Sex                      F\n",
            "Duration                21\n",
            "Amount                9005\n",
            "Name: 557, dtype: object\n",
            "\n",
            "Transformed Data:\n",
            "[   0.    0.    0.    0.    0.    1.    1.    0.   21. 9005.]\n"
          ]
        }
      ]
    }
  ]
}